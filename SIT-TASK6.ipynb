{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b62aac0",
   "metadata": {},
   "source": [
    "# **SIT731**\n",
    "**Name: Addala Srivatsa Gaurav**\n",
    "\n",
    "**Student ID: S223872808**\n",
    "\n",
    "**Email id: asgaurav9@gmail.com**\n",
    "\n",
    "**I am Post Graduate Student(SIT731)**\n",
    "\n",
    "# Introduction\n",
    "This project delves into the nycflights13 dataset, capturing details of 336,776 flights departing from New York's EWR, JFK, and LGA airports to destinations and nearby regions in 2013. Utilizing pandas, we establish a connection with an SQLite database and replicate SQL queries for comprehensive data analysis. Five crucial datasets, including flight information, carrier details, airport data, plane specifics, and meteorological records, are incorporated. The analysis is presented in a Jupyter/IPython notebook using jupytext, combining a .py source file with a .ipynb notebook for effective code interpretation. The objective is to showcase pandas' capabilities in data exploration and manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b09f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "pd.set_option(\"display.notebook_repr_html\", False)\n",
    "\n",
    "# Load data from CSV files\n",
    "airlines = pd.read_csv(\"airlines.csv\", comment='#')\n",
    "airports = pd.read_csv(\"airports.csv\", comment=\"#\")\n",
    "flights = pd.read_csv(\"flights.csv\", comment=\"#\")\n",
    "planes = pd.read_csv(\"planes.csv\", comment=\"#\")\n",
    "weather = pd.read_csv(\"weather.csv\", comment=\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65c5329",
   "metadata": {},
   "source": [
    "This code utilizes pandas to load data from CSV files ('airlines.csv', 'airports.csv', 'flights.csv', 'planes.csv', 'weather.csv'). It sets display options and prints the first few rows of each DataFrame (airlines, airports, flights, planes, weather) for initial exploration, providing an overview of the dataset structure and content. The comment='#' parameter excludes lines starting with '#' in the CSV files during loading. The code also imports necessary libraries such as sqlite3, numpy, matplotlib, and seaborn for further analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd127a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile, os.path\n",
    "dbfile = os.path.join(tempfile.mkdtemp(), \"nyc.db\")\n",
    "print(dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ba91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(dbfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines.to_sql(\"airlines\", conn, index=False)\n",
    "airports.to_sql(\"airports\", conn, index=False)\n",
    "flights.to_sql(\"flights\", conn, index=False)\n",
    "planes.to_sql(\"planes\", conn, index=False)\n",
    "weather.to_sql(\"weather\", conn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b866a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", conn)\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6710449",
   "metadata": {},
   "source": [
    "This Python code creates a temporary SQLite database file ('nyc.db') using tempfile and os.path. It establishes a connection to the database using sqlite3. Data from DataFrames (airlines, airports, flights, planes, weather) is then stored in corresponding tables in the SQLite database. The tables' names are queried and printed to verify successful creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118af44b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Pandas Equivalent\n",
    "task1_my = planes['engine'].drop_duplicates().reset_index(drop=True).to_frame()\n",
    "\n",
    "# SQL Query\n",
    "task1_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT DISTINCT engine FROM planes\n",
    "\"\"\", conn)\n",
    "\n",
    "# Check for equality\n",
    "pd.testing.assert_frame_equal(task1_sql, task1_my)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d62d9d9",
   "metadata": {},
   "source": [
    "This code shows the equivalent Pandas implementation of a SQL query selecting distinct values from the 'engine' column in the 'planes' table. The results from both SQL and Pandas are compared using pd.testing.assert_frame_equal. If there is no error, it means the results match. The SQL and Pandas results are then printed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a62e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Code:\n",
    "task2_my = planes[['type', 'engine']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# SQL Code:\n",
    "task2_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT DISTINCT type, engine FROM planes\n",
    "\"\"\", conn)\n",
    "\n",
    "# Check for equality\n",
    "pd.testing.assert_frame_equal(task2_sql, task2_my)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff46bf23",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This code demonstrates the equivalent Pandas implementation of a SQL query. The goal is to select distinct combinations of values from the 'type' and 'engine' columns in the 'planes' table. The results from both SQL and Pandas are compared using pd.testing.assert_frame_equal. If there is no error, it means the results match. The SQL and Pandas results are then printed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc96af",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# SQL Query:\n",
    "task3_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT COUNT(*), engine\n",
    "    FROM planes\n",
    "    GROUP BY engine\n",
    "\"\"\", conn)\n",
    "\n",
    "# Pandas Equivalent\n",
    "task3_my = planes.groupby('engine').size().reset_index(name='count').sort_values('engine')\n",
    "\n",
    "# Reorder the columns to match the SQL result\n",
    "task3_my = task3_my[['count', 'engine']]\n",
    "\n",
    "# Compare SQL and Pandas results \n",
    "try:\n",
    "    pd.testing.assert_frame_equal(task3_sql, task3_my, check_dtype=False)\n",
    "except AssertionError as e:\n",
    "    print(f\"\\nAssertionError: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7878d5c4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This code represents an SQL query and its Pandas equivalent. Both aim to count the occurrences of each unique 'engine' value in the 'planes' table. The SQL and Pandas results are then compared using pd.testing.assert_frame_equal. The check_dtype=False parameter is used to ignore data type differences that might arise from certain operations. If there is no error, it indicates that the results are equivalent. Finally, the SQL and Pandas results are printed for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e15611",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# SQL Query\n",
    "task4_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT COUNT(*) AS count, engine, type FROM planes GROUP BY engine, type\n",
    "\"\"\", conn)\n",
    "\n",
    "# Pandas Equivalent\n",
    "task4_pandas = planes.groupby(['engine', 'type']).size().reset_index(name='count')[['count', 'engine', 'type']]\n",
    "\n",
    "\n",
    "# Compare the results\n",
    "pd.testing.assert_frame_equal(task4_sql, task4_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00066676",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This code consists of an SQL query and its Pandas equivalent. Both queries aim to count the occurrences of unique combinations of 'engine' and 'type' values in the 'planes' table. The SQL and Pandas results are then compared using pd.testing.assert_frame_equal. If there is no error, it indicates that the results are equivalent. Finally, the SQL and Pandas results are printed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78628b41",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# SQL Query\n",
    "task5_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT MIN(year) AS min_year, AVG(year) AS avg_year, MAX(year) AS max_year, engine, manufacturer\n",
    "    FROM planes\n",
    "    GROUP BY engine, manufacturer\n",
    "\"\"\", conn)\n",
    "\n",
    "\n",
    "# Pandas equivalent code for the SQL query\n",
    "task5_pandas = planes.groupby(['engine', 'manufacturer']).agg({\n",
    "    'year': ['min', 'mean', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten the multi-level columns and rename\n",
    "task5_pandas.columns = ['engine', 'manufacturer', 'min_year', 'avg_year', 'max_year']\n",
    "\n",
    "# Reorder columns to match SQL result\n",
    "task5_pandas = task5_pandas[['min_year', 'avg_year', 'max_year', 'engine', 'manufacturer']]\n",
    "\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(task5_sql, task5_pandas, check_like=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccf24ea",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The SQL query retrieves the minimum, average, and maximum 'year' values grouped by 'engine' and 'manufacturer' from the 'planes' table. The Pandas equivalent achieves the same using the groupby and agg functions, creating a DataFrame with consistent column names. The results are compared using pd.testing.assert_frame_equal. If no error is raised, the Pandas implementation is consistent with the SQL query. The DataFrames are printed for verification.\n",
    "\n",
    "\n",
    "SQL Query\n",
    "task6_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT * FROM planes WHERE speed IS NOT NULL\n",
    "\"\"\", conn)\n",
    "\n",
    "Pandas equivalent code for the SQL query\n",
    "task6_pandas = planes[planes['speed'].notnull()]\n",
    "\n",
    "task6_pandas = task6_pandas.reset_index(drop=True)\n",
    "\n",
    "\n",
    "Compare the DataFrames\n",
    "pd.testing.assert_frame_equal(task6_sql, task6_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9464ce",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The SQL query retrieves all records from the 'planes' table where the 'speed' column is not null. The Pandas equivalent filters the DataFrame using boolean indexing. The DataFrames are compared using pd.testing.assert_frame_equal. If no error is raised, the Pandas implementation is consistent with the SQL query. Results for both SQL and Pandas are printed for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6133a2df",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# SQL Query\n",
    "task7_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT tailnum FROM planes\n",
    "    WHERE seats BETWEEN 150 AND 210 AND year >= 2011\n",
    "\"\"\", conn)\n",
    "\n",
    "# Pandas equivalent code for the SQL query\n",
    "task7_pandas = planes[(planes['seats'].between(150, 210)) & (planes['year'] >= 2011)][['tailnum']]\n",
    "\n",
    "task7_pandas = task7_pandas.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(task7_sql, task7_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47a0c84",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The SQL query retrieves 'tailnum' values from the 'planes' table where 'seats' fall between 150 and 210, and 'year' is greater than or equal to 2011. The Pandas equivalent uses boolean indexing to filter the DataFrame accordingly. Both results are compared using pd.testing.assert_frame_equal for consistency.\n",
    "\n",
    "SQL Query\n",
    "task8_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT tailnum, manufacturer, seats FROM planes\n",
    "    WHERE manufacturer IN (\"BOEING\", \"AIRBUS\", \"EMBRAER\") AND seats > 390\n",
    "\"\"\", conn)\n",
    "\n",
    "\n",
    "Pandas equivalent code for the SQL query\n",
    "manufacturers_list = [\"BOEING\", \"AIRBUS\", \"EMBRAER\"]\n",
    "task8_pandas = planes[(planes['manufacturer'].isin(manufacturers_list)) & (planes['seats'] > 390)][['tailnum', 'manufacturer', 'seats']]\n",
    "\n",
    "task8_pandas = task8_pandas.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(task8_sql, task8_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e376421",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The SQL query extracts 'tailnum,' 'manufacturer,' and 'seats' from the 'planes' table where 'manufacturer' is in a specified list (\"BOEING,\" \"AIRBUS,\" \"EMBRAER\") and 'seats' exceed 390. The Pandas equivalent utilizes boolean indexing with isin and logical conditions to filter the DataFrame accordingly. The results are compared using pd.testing.assert_frame_equal to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19826f3a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# SQL Query\n",
    "task9_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT DISTINCT year, seats FROM planes\n",
    "    WHERE year >= 2012\n",
    "    ORDER BY year ASC, seats DESC\n",
    "\"\"\", conn)\n",
    "\n",
    "# Pandas equivalent code for the SQL query\n",
    "task9_pandas = planes[planes['year'] >= 2012][['year', 'seats']].sort_values(by=['year', 'seats'], ascending=[True, False]).drop_duplicates()\n",
    "\n",
    "task9_pandas = task9_pandas.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(task9_sql, task9_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c39bc0b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The SQL query selects distinct 'year' and 'seats' from the 'planes' table where 'year' is greater than or equal to 2012. It orders the results by 'year' in ascending order and 'seats' in descending order. The Pandas equivalent uses boolean indexing, column selection, sorting, and dropping duplicates to achieve the same result. The DataFrames are then compared using pd.testing.assert_frame_equal for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7331d399",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# SQL Query\n",
    "task10_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT DISTINCT year, seats FROM planes\n",
    "    WHERE year >= 2012\n",
    "    ORDER BY seats DESC, year ASC\n",
    "\"\"\", conn)\n",
    "\n",
    "\n",
    "# Pandas equivalent code for the SQL query\n",
    "task10_pandas = planes[planes['year'] >= 2012][['year', 'seats']].sort_values(by=['seats', 'year'], ascending=[False, True]).drop_duplicates()\n",
    "\n",
    "task10_pandas = task10_pandas.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(task10_sql, task10_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87671c32",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The SQL query selects distinct 'year' and 'seats' from the 'planes' table where 'year' is greater than or equal to 2012. It orders the results by 'seats' in descending order and 'year' in ascending order. The Pandas equivalent achieves the same result using boolean indexing, column selection, sorting, and dropping duplicates. The DataFrames are compared for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fdc143",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# SQL Query\n",
    "task11_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) FROM planes\n",
    "    WHERE seats > 200\n",
    "    GROUP BY manufacturer\n",
    "\"\"\", conn)\n",
    "\n",
    "\n",
    "# Pandas equivalent code for the SQL query\n",
    "task11_pandas = planes[planes['seats'] > 200].groupby('manufacturer').size().reset_index(name='COUNT(*)')\n",
    "\n",
    "task11_pandas = task11_pandas.sort_values(by=['manufacturer']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(task11_sql, task11_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e12357",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The SQL query retrieves the count of planes with more than 200 seats for each manufacturer from the 'planes' table. The Pandas equivalent filters the DataFrame based on seats, groups by the manufacturer, calculates the size, and resets the index for consistency. Both results are compared using assert_frame_equal to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f6c94",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# SQL Query\n",
    "task12_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) FROM planes\n",
    "    GROUP BY manufacturer\n",
    "    HAVING COUNT(*) > 10\n",
    "\"\"\", conn)\n",
    "\n",
    "# Pandas equivalent code for the SQL query\n",
    "manufacturer_counts = planes.groupby('manufacturer').size().reset_index(name='COUNT(*)')\n",
    "task12_pandas = manufacturer_counts[manufacturer_counts['COUNT(*)'] > 10]\n",
    "\n",
    "task12_pandas = task12_pandas.sort_values(by=['manufacturer']).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(task12_sql, task12_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b16584",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The SQL query retrieves the count of planes for each manufacturer from the 'planes' table and filters only those with counts greater than 10 using the having clause. The Pandas equivalent code calculates the manufacturer counts, filters based on the count condition, and resets the index for consistency. Both results are compared using assert_frame_equal to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b67cf7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# SQL Query for Task 13 with HAVING clause\n",
    "task13_sql= pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) AS count\n",
    "    FROM planes\n",
    "    WHERE seats > 200\n",
    "    GROUP BY manufacturer\n",
    "    HAVING COUNT(*) > 10;\n",
    "\"\"\", conn)\n",
    "\n",
    "# Pandas Equivalent for Task 13 with HAVING clause\n",
    "task13_pandas= planes[planes['seats'] > 200].groupby('manufacturer').size().reset_index(name='count')\n",
    "task13_pandas= task13_pandas[task13_pandas['count'] > 10].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(task13_sql, task13_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529ff7b2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Task 13 SQL query filters planes with more than 200 seats, groups them by manufacturer, and retrieves the count for each group, applying a HAVING clause to select only those with counts exceeding 10. The Pandas equivalent code follows a similar approach, calculating manufacturer counts, filtering based on the count condition, and ensuring consistent indexing. The results are printed and compared using assert_frame_equal to validate equivalence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9166edbb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# SQL Query for Task 14\n",
    "task14_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT manufacturer, COUNT(*) AS howmany\n",
    "    FROM planes\n",
    "    GROUP BY manufacturer\n",
    "    ORDER BY howmany DESC\n",
    "    LIMIT 10;\n",
    "\"\"\", conn)\n",
    "\n",
    "# Pandas Equivalent \n",
    "task14_pandas = planes.groupby('manufacturer').size().reset_index(name='howmany')\n",
    "task14_pandas = task14_pandas.sort_values(by='howmany', ascending=False).head(10).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(task14_sql, task14_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ae6cd",
   "metadata": {},
   "source": [
    "\n",
    "Task 14 SQL query counts the number of planes for each manufacturer, orders the result by count in descending order, and limits the output to the top 10 manufacturers. The Pandas equivalent code utilizes groupby and size to obtain manufacturer counts, sorts in descending order, and selects the top 10. SQL and Pandas results are printed and compared using assert_frame_equal to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d1c91",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# SQL Query for Task 15\n",
    "task15_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT\n",
    "        flights.*,\n",
    "        planes.year AS plane_year,\n",
    "        planes.speed AS plane_speed,\n",
    "        planes.seats AS plane_seats\n",
    "    FROM flights\n",
    "    LEFT JOIN planes ON flights.tailnum=planes.tailnum\n",
    "\"\"\", conn)\n",
    "\n",
    "# Pandas Equivalent \n",
    "task15_pandas = flights.merge(planes[['tailnum', 'year', 'speed', 'seats']],\n",
    "                              how='left', left_on='tailnum', right_on='tailnum')\n",
    "\n",
    "# Rename columns to match the SQL result\n",
    "task15_pandas.columns = ['year', 'month', 'day', 'dep_time', 'sched_dep_time', 'dep_delay',\n",
    "                         'arr_time', 'sched_arr_time', 'arr_delay', 'carrier', 'flight',\n",
    "                         'tailnum', 'origin', 'dest', 'air_time', 'distance', 'hour', 'minute',\n",
    "                         'time_hour', 'plane_year', 'plane_speed', 'plane_seats']\n",
    "\n",
    "\n",
    "\n",
    "# Compare the results\n",
    "pd.testing.assert_frame_equal(task15_sql, task15_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d701d09e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Task 15 SQL query performs a LEFT JOIN between the flights and planes tables on the 'tailnum' column, including additional columns from the planes table. The Pandas equivalent achieves this using the merge function without pd.merge, matching on 'tailnum'. Column names are adjusted to align with the SQL result. The Pandas and SQL results are printed, and assert_frame_equal ensures their equality. The code leverages merge for a concise alternative to pd.merge, improving code readability and maintaining consistency with SQL logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfbd21a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# SQL Query for Task 16\n",
    "task16_sql = pd.read_sql_query('''\n",
    "    SELECT planes.*, airlines.*\n",
    "    FROM (\n",
    "        SELECT DISTINCT carrier, tailnum\n",
    "        FROM flights\n",
    "    ) AS cartail\n",
    "    INNER JOIN planes ON cartail.tailnum = planes.tailnum\n",
    "    INNER JOIN airlines ON cartail.carrier = airlines.carrier\n",
    "''', conn)\n",
    "\n",
    "# Creating DataFrame cartail\n",
    "cartail = flights[['carrier', 'tailnum']].drop_duplicates()\n",
    "\n",
    "# Inner join with planes DataFrame\n",
    "task16_my = pd.merge(cartail, planes, on='tailnum', how='inner')\n",
    "\n",
    "# Inner join with airlines DataFrame\n",
    "task16_my = pd.merge(task16_my, airlines, on='carrier', how='inner')\n",
    "\n",
    "# Explicitly order the columns in both DataFrames\n",
    "task16_my = task16_my[['tailnum', 'year', 'type', 'manufacturer', 'model', 'engines', 'seats', 'speed', 'engine', 'carrier', 'name']]\n",
    "\n",
    "# Sorting the DataFrame to ensure order consistency\n",
    "task16_my.sort_values(by=['tailnum', 'carrier'], inplace=True)\n",
    "\n",
    "# Resetting the index\n",
    "task16_my.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# To check if SQL and Pandas results are equal\n",
    "pd.testing.assert_frame_equal(task16_sql, task16_my)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf30f0e4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Task 16 SQL query selects unique combinations of carrier and tailnum from the flights table and performs INNER JOINs with the planes and airlines tables. The Pandas equivalent achieves this by using drop_duplicates on the relevant columns, then merging with planes and airlines separately. The results are printed for both SQL and Pandas, and assert_frame_equal ensures their equality. This approach ensures matching results in both SQL and Pandas by explicitly defining the intermediate steps and combining them, maintaining the logic of the SQL query in the Pandas code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ef7183",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Post Graduate Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9980078b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    " #Equivalent SQL Query\n",
    "task17_sql = pd.read_sql_query(\"\"\"\n",
    "    SELECT flights2.*, atemp, ahumid\n",
    "    FROM (\n",
    "        SELECT * FROM flights WHERE origin='EWR'\n",
    "    ) AS flights2\n",
    "    LEFT JOIN (\n",
    "        SELECT\n",
    "            year, month, day,\n",
    "            AVG(temp) AS atemp,\n",
    "            AVG(humid) AS ahumid\n",
    "        FROM weather\n",
    "        WHERE origin='EWR'\n",
    "        GROUP BY year, month, day\n",
    "    ) AS weather2\n",
    "    ON flights2.year=weather2.year\n",
    "    AND flights2.month=weather2.month\n",
    "    AND flights2.day=weather2.day;\n",
    "\"\"\", conn)\n",
    "\n",
    "# Pandas Equivalent\n",
    "flights2 = flights[flights['origin'] == 'EWR'].copy()\n",
    "weather2 = weather[weather['origin'] == 'EWR'].groupby(['year', 'month', 'day']).agg(atemp=('temp', 'mean'), ahumid=('humid', 'mean')).reset_index()\n",
    "\n",
    "task17_pandas = pd.merge(flights2, weather2, on=['year', 'month', 'day'], how='left')\n",
    "\n",
    "\n",
    "\n",
    "pd.testing.assert_frame_equal(task17_sql, task17_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e993166",
   "metadata": {},
   "source": [
    "For Task 17, the Pandas code selects flights and weather data for the 'EWR' origin. It calculates daily average temperature ('atemp') and humidity ('ahumid') from the weather data, grouping by year, month, and day. A left join is performed on flights' date-related columns, replicating the SQL logic. The results are printed for both SQL and Pandas, and assert_frame_equal is employed for validation, considering ordering and data types for consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea259f4c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "# **Conclusion:**\n",
    "In this analysis, data from the 'nycflights13' dataset was processed using both SQL queries and Pandas operations in Python. The tasks covered a range of operations, including selecting unique values, filtering based on conditions, aggregating data, and performing joins.\n",
    "\n",
    "Tasks 1 to 5 involved basic queries, such as selecting distinct engine types and type-engine pairs, counting occurrences of engine types, and finding combinations of engine types and plane types with their counts and order statistics. Tasks 6 to 10 focused on more complex queries, including aggregating and summarizing data based on conditions, such as finding minimum, average, and maximum years for each combination of engine and manufacturer.\n",
    "\n",
    "Tasks 11 to 17 introduced additional complexity with filtering and joining operations. The queries involved selecting manufacturers with more than 200 seats and ordering the results. Task 13 included a 'HAVING' clause in both SQL and Pandas, emphasizing a condition on the grouped data. Tasks 15 and 16 demonstrated joining tables to retrieve specific columns from related tables.\n",
    "\n",
    "Throughout the tasks, the Pandas code closely mirrored the SQL queries, ensuring equivalent results. The 'assert_frame_equal' method was employed to validate the consistency of results, considering both data values and column order.\n",
    "\n",
    "Overall, the Pandas library provides a powerful and flexible alternative to SQL for data manipulation and analysis, offering a seamless transition for those familiar with SQL queries. The combination of SQL and Pandas allows for comprehensive data exploration and analysis, providing insights into the 'nycflights13' dataset."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "auto:light,ipynb",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
